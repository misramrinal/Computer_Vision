{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c06bba1",
   "metadata": {},
   "source": [
    "Name: Mrinal Misra\n",
    "\n",
    "Roll: 121CS0132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e213104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.24.4 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f176e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.datassets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD,Adam,Nadam,AdamW\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner import RandomSearch, GridSearch, BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b163250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.4\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1567e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22af2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a83f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d7a2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i in range(15):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "    plt.title(f\"Label: {train_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cbba839",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = train_images[:1000]\n",
    "y_trn = train_labels[:1000]\n",
    "X_tst = test_images[:500]\n",
    "y_tst = test_labels[:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64799bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 28, 28), (1000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trn.shape,y_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b37a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = X_trn.reshape((X_trn.shape[0], 28 * 28)).astype('float32') / 255\n",
    "X_tst = X_tst.reshape((X_tst.shape[0], 28 * 28)).astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32820f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  1\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 2.6412 - accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.6385 - accuracy: 0.0980\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.5544 - accuracy: 0.1180\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.5167 - accuracy: 0.1100\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.5503 - accuracy: 0.1080\n",
      "Mean Test Accuracy: 0.20999999344348907\n"
     ]
    }
   ],
   "source": [
    "# Number of times to call the model\n",
    "num_calls = 1\n",
    "# List to store test accuracies\n",
    "test_accuracies = []\n",
    "for i in range(num_calls):\n",
    " print(\"step: \",i+1)\n",
    " # Define, compile, and train the model\n",
    " \n",
    " model = keras.Sequential()\n",
    " model.add(Dense(128, activation='sigmoid',input_shape=(784,)))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(64, activation='tanh'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(32, activation='tanh'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(16, activation='tanh'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "\n",
    " sgd = SGD(learning_rate=0.01) \n",
    " model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    " model.fit(X_trn, y_trn, epochs=5, batch_size=32)\n",
    " \n",
    " # Evaluate the model on test data\n",
    " _, test_accuracy = model.evaluate(X_tst, y_tst,verbose=0)\n",
    " \n",
    " # Append test accuracy to the list\n",
    " test_accuracies.append(test_accuracy)\n",
    "# Compute the mean of test accuracies\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print(\"Mean Test Accuracy:\", mean_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31efb09d",
   "metadata": {},
   "source": [
    "Mean Accuracy for Sigmoid and Tanh Layers : 0.20999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bb6f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    " \n",
    " hp_neurons = hp.Int('neurons', min_value=32, max_value=512, step=32)\n",
    " \n",
    " model = keras.Sequential()\n",
    " model.add(Dense(units=hp_neurons, activation='sigmoid',input_shape=(784,)))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(64, activation='tanh'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(32, activation='tanh'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(16, activation='tanh'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(10, activation='softmax'))\n",
    " \n",
    " # Tune learning rate and batch size\n",
    " hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.15])\n",
    " hp_batch_size = hp.Choice('batch_size', values=[4, 8, 16])\n",
    " # Compile the model\n",
    " model.compile(optimizer=keras.optimizers.SGD(learning_rate=hp_learning_rate),\n",
    " loss='sparse_categorical_crossentropy',\n",
    " metrics=['accuracy'])\n",
    " \n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7961450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the tuner\n",
    "tuner = RandomSearch(\n",
    " build_model,\n",
    " objective='val_accuracy',\n",
    " max_trials=10,\n",
    " executions_per_trial=1,\n",
    " directory='keras_tuner_mnists',\n",
    " project_name='mnist_hyperparameters'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1307f64a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 11s]\n",
      "val_accuracy: 0.12200000137090683\n",
      "\n",
      "Best val_accuracy So Far: 0.6019999980926514\n",
      "Total elapsed time: 00h 02m 06s\n"
     ]
    }
   ],
   "source": [
    "hp_batch_size = tuner.oracle.get_space()['batch_size']\n",
    "tuner.search(X_trn, y_trn, epochs=15, validation_data=(X_tst, y_tst), batch_size=hp_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe418ca",
   "metadata": {},
   "source": [
    "Best accuracy with hyperparameter tuning: 0.601999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ffd5da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neurons: 64\n",
      "Best learning rate: 0.1\n",
      "Best batch size: 30\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0868 - accuracy: 0.6020\n",
      "Test accuracy of the best model: 0.6019999980926514\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=20)[0]\n",
    "best_neurons = best_hps.get('neurons')\n",
    "best_learning_rate = best_hps.get('learning_rate')\n",
    "best_batch_size = best_hps.get('batch_size')\n",
    "print(f\"Best number of neurons: {best_neurons}\")\n",
    "print(f\"Best learning rate: {best_learning_rate}\")\n",
    "print(f\"Best batch size: {best_batch_size}\")\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(X_tst, y_tst)\n",
    "print(f\"Test accuracy of the best model: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31c75e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57178 (223.35 KB)\n",
      "Trainable params: 57178 (223.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b9036",
   "metadata": {},
   "source": [
    "Model-1: 4 hidden layers having 128, 64, 32, 16 number of neurons \n",
    "respectively with activation function sigmoid, tanh, relu and selu respectively \n",
    "and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as SGD\n",
    "with batch size set to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2db82f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  1\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 8.8968 - accuracy: 0.0950\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7539 - accuracy: 0.0850\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2613 - accuracy: 0.1120\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3296 - accuracy: 0.1000\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.4769 - accuracy: 0.0920\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0468 - accuracy: 0.1080\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0153 - accuracy: 0.1150\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8591 - accuracy: 0.1170\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7724 - accuracy: 0.1130\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8521 - accuracy: 0.1160\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4960 - accuracy: 0.1210\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8512 - accuracy: 0.1180\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8903 - accuracy: 0.1170\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8507 - accuracy: 0.1090\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7711 - accuracy: 0.1230\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6288 - accuracy: 0.1240\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9010 - accuracy: 0.1180\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7627 - accuracy: 0.1120\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8129 - accuracy: 0.1120\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9494 - accuracy: 0.1150\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7434 - accuracy: 0.1110\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8706 - accuracy: 0.1040\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7990 - accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8381 - accuracy: 0.1090\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8426 - accuracy: 0.1100\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6591 - accuracy: 0.1150\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0002 - accuracy: 0.1070\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7271 - accuracy: 0.1210\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7803 - accuracy: 0.1200\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0789 - accuracy: 0.1170\n",
      "step:  2\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 7.2365 - accuracy: 0.0790\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7287 - accuracy: 0.0940\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2878 - accuracy: 0.0950\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5613 - accuracy: 0.0980\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0115 - accuracy: 0.0890\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0935 - accuracy: 0.0940\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9034 - accuracy: 0.1000\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9694 - accuracy: 0.1000\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0049 - accuracy: 0.1190\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.1064 - accuracy: 0.0880\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7794 - accuracy: 0.0920\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9974 - accuracy: 0.0870\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7051 - accuracy: 0.1030\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9474 - accuracy: 0.1070\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6413 - accuracy: 0.1050\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9565 - accuracy: 0.0850\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9605 - accuracy: 0.1100\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9512 - accuracy: 0.1010\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7930 - accuracy: 0.1020\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9318 - accuracy: 0.0950\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9989 - accuracy: 0.1060\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8975 - accuracy: 0.1090\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0500 - accuracy: 0.0800\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8442 - accuracy: 0.1050\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8207 - accuracy: 0.1030\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.5623 - accuracy: 0.0980\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4852 - accuracy: 0.1010\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8591 - accuracy: 0.0970\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0978 - accuracy: 0.0950\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6719 - accuracy: 0.0930\n",
      "step:  3\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 8.8892 - accuracy: 0.0690\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5728 - accuracy: 0.0920\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9465 - accuracy: 0.0900\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.4055 - accuracy: 0.0890\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.2199 - accuracy: 0.0920\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 8.4596 - accuracy: 0.0930\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 8.5009 - accuracy: 0.0870\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.8603 - accuracy: 0.0870\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.8960 - accuracy: 0.0910\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4374 - accuracy: 0.0970\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4263 - accuracy: 0.0790\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2470 - accuracy: 0.0930\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4196 - accuracy: 0.0920\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2063 - accuracy: 0.0940\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.5489 - accuracy: 0.0940\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.4387 - accuracy: 0.0850\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2829 - accuracy: 0.0880\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1908 - accuracy: 0.0910\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9363 - accuracy: 0.0930\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3902 - accuracy: 0.0890\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1242 - accuracy: 0.0950\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.3762 - accuracy: 0.0870\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.3366 - accuracy: 0.0890\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9698 - accuracy: 0.0900\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.2476 - accuracy: 0.0920\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.9810 - accuracy: 0.0900\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.2216 - accuracy: 0.0820\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0462 - accuracy: 0.0980\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.0645 - accuracy: 0.0950\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.8850 - accuracy: 0.0950\n",
      "step:  4\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 7.6876 - accuracy: 0.0820\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4640 - accuracy: 0.1090\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9970 - accuracy: 0.1040\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3146 - accuracy: 0.0950\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3365 - accuracy: 0.1000\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2539 - accuracy: 0.0960\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.2709 - accuracy: 0.1020\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0493 - accuracy: 0.0910\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9577 - accuracy: 0.1030\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.5907 - accuracy: 0.0950\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9507 - accuracy: 0.1020\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8869 - accuracy: 0.0940\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8451 - accuracy: 0.1000\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6058 - accuracy: 0.1020\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8476 - accuracy: 0.0980\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5551 - accuracy: 0.1140\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1627 - accuracy: 0.1030\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8283 - accuracy: 0.1080\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8577 - accuracy: 0.0990\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0199 - accuracy: 0.1110\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7560 - accuracy: 0.0990\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8723 - accuracy: 0.1060\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7246 - accuracy: 0.1030\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8200 - accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.1709 - accuracy: 0.0890\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7724 - accuracy: 0.1030\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6898 - accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8929 - accuracy: 0.1020\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7424 - accuracy: 0.0990\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.5955 - accuracy: 0.1250\n",
      "step:  5\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 8.5114 - accuracy: 0.0950\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8459 - accuracy: 0.1010\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7901 - accuracy: 0.1050\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.3093 - accuracy: 0.0910\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3129 - accuracy: 0.1010\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.2044 - accuracy: 0.1000\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7598 - accuracy: 0.0970\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.3697 - accuracy: 0.0970\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1322 - accuracy: 0.1060\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1465 - accuracy: 0.0930\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1966 - accuracy: 0.1000\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0217 - accuracy: 0.1020\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0025 - accuracy: 0.0850\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0321 - accuracy: 0.1000\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8766 - accuracy: 0.1010\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8932 - accuracy: 0.1090\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9953 - accuracy: 0.0930\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7282 - accuracy: 0.1050\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6192 - accuracy: 0.0940\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0197 - accuracy: 0.1020\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9268 - accuracy: 0.0980\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9823 - accuracy: 0.1040\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8039 - accuracy: 0.1020\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7250 - accuracy: 0.1050\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6475 - accuracy: 0.0980\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9269 - accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6477 - accuracy: 0.0920\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7707 - accuracy: 0.1020\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8435 - accuracy: 0.1060\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6786 - accuracy: 0.1090\n",
      "step:  6\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 8.1684 - accuracy: 0.1030\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.6882 - accuracy: 0.1130\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9532 - accuracy: 0.1160\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9847 - accuracy: 0.1130\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9122 - accuracy: 0.1210\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.8584 - accuracy: 0.1130\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9107 - accuracy: 0.1090\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8011 - accuracy: 0.1160\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2969 - accuracy: 0.1130\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7898 - accuracy: 0.1040\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2364 - accuracy: 0.1010\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7227 - accuracy: 0.1110\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4862 - accuracy: 0.0970\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3790 - accuracy: 0.1150\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3908 - accuracy: 0.0940\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3461 - accuracy: 0.0960\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.7255 - accuracy: 0.1040\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2424 - accuracy: 0.1010\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4474 - accuracy: 0.1180\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4342 - accuracy: 0.1080\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4578 - accuracy: 0.1010\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3021 - accuracy: 0.1080\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.6463 - accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6475 - accuracy: 0.1020\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4846 - accuracy: 0.0930\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7024 - accuracy: 0.1040\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5024 - accuracy: 0.0870\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8026 - accuracy: 0.1060\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4659 - accuracy: 0.0900\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5021 - accuracy: 0.0880\n",
      "step:  7\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 9.1159 - accuracy: 0.0840\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4539 - accuracy: 0.1110\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.5679 - accuracy: 0.1080\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.3012 - accuracy: 0.0890\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8050 - accuracy: 0.1160\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0067 - accuracy: 0.1010\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7337 - accuracy: 0.1100\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7774 - accuracy: 0.1070\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7327 - accuracy: 0.1140\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9775 - accuracy: 0.0900\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9183 - accuracy: 0.1010\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0879 - accuracy: 0.0930\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8639 - accuracy: 0.0920\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8178 - accuracy: 0.0940\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9328 - accuracy: 0.1100\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9871 - accuracy: 0.0870\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.4787 - accuracy: 0.0990\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1198 - accuracy: 0.0950\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0003 - accuracy: 0.1100\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0158 - accuracy: 0.0990\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7408 - accuracy: 0.1120\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8206 - accuracy: 0.1110\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7117 - accuracy: 0.1060\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9814 - accuracy: 0.0950\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8529 - accuracy: 0.1060\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7290 - accuracy: 0.0870\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7339 - accuracy: 0.1050\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8266 - accuracy: 0.1020\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8435 - accuracy: 0.1060\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6435 - accuracy: 0.1120\n",
      "step:  8\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 9.3408 - accuracy: 0.0910\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.2753 - accuracy: 0.0960\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5269 - accuracy: 0.0910\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0623 - accuracy: 0.0910\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9598 - accuracy: 0.1000\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6560 - accuracy: 0.0840\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8120 - accuracy: 0.0940\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0576 - accuracy: 0.0840\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8488 - accuracy: 0.1080\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9287 - accuracy: 0.0950\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6209 - accuracy: 0.1070\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9160 - accuracy: 0.1040\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9586 - accuracy: 0.0790\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6747 - accuracy: 0.1080\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6685 - accuracy: 0.0950\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7086 - accuracy: 0.0980\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9968 - accuracy: 0.0830\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7338 - accuracy: 0.1030\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6780 - accuracy: 0.1100\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9558 - accuracy: 0.0970\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9410 - accuracy: 0.0950\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6218 - accuracy: 0.1100\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7730 - accuracy: 0.0980\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8189 - accuracy: 0.0920\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9988 - accuracy: 0.1060\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9195 - accuracy: 0.0920\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5598 - accuracy: 0.1030\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9011 - accuracy: 0.0960\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7089 - accuracy: 0.1010\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7128 - accuracy: 0.0950\n",
      "step:  9\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 10.9229 - accuracy: 0.0720\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.5878 - accuracy: 0.0920\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7013 - accuracy: 0.0870\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.9512 - accuracy: 0.1010\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0212 - accuracy: 0.1020\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.4067 - accuracy: 0.0990\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2125 - accuracy: 0.0950\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.1616 - accuracy: 0.0900\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.3814 - accuracy: 0.0990\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 5.0249 - accuracy: 0.0940\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8618 - accuracy: 0.0970\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.9678 - accuracy: 0.0870\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.6609 - accuracy: 0.0900\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0372 - accuracy: 0.1040\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7921 - accuracy: 0.0940\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6026 - accuracy: 0.1010\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8789 - accuracy: 0.1010\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0215 - accuracy: 0.0930\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8029 - accuracy: 0.1030\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0765 - accuracy: 0.1000\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8257 - accuracy: 0.1050\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8055 - accuracy: 0.0980\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5974 - accuracy: 0.1090\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0504 - accuracy: 0.0910\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7930 - accuracy: 0.1040\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8031 - accuracy: 0.0940\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6734 - accuracy: 0.1020\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9362 - accuracy: 0.0990\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6878 - accuracy: 0.0990\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8504 - accuracy: 0.0960\n",
      "step:  10\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 8.6985 - accuracy: 0.0970\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 6.0801 - accuracy: 0.1020\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0769 - accuracy: 0.0990\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.6068 - accuracy: 0.0980\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2507 - accuracy: 0.0910\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1993 - accuracy: 0.0950\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7343 - accuracy: 0.0940\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0370 - accuracy: 0.0940\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7472 - accuracy: 0.0950\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8105 - accuracy: 0.0900\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8857 - accuracy: 0.0840\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7085 - accuracy: 0.0960\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8217 - accuracy: 0.0920\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7721 - accuracy: 0.0890\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6817 - accuracy: 0.0940\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6141 - accuracy: 0.0910\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.4421 - accuracy: 0.1000\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8829 - accuracy: 0.0940\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6836 - accuracy: 0.1020\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7945 - accuracy: 0.0920\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0304 - accuracy: 0.0980\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7551 - accuracy: 0.0960\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6763 - accuracy: 0.0950\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8150 - accuracy: 0.0910\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8379 - accuracy: 0.0960\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8485 - accuracy: 0.0910\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.6758 - accuracy: 0.0950\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.8072 - accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.5511 - accuracy: 0.0950\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7707 - accuracy: 0.0970\n",
      "Mean Test Accuracy: 0.10180000215768814\n"
     ]
    }
   ],
   "source": [
    "# Number of times to call the model\n",
    "num_calls = 10\n",
    "# List to store test accuracies\n",
    "test_accuracies = []\n",
    "for i in range(num_calls):\n",
    " print(\"step: \",i+1)\n",
    " # Define, compile, and train the model\n",
    " \n",
    " model = keras.Sequential()\n",
    " model.add(Dense(128, activation='sigmoid',input_shape=(784,)))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(64, activation='tanh'))\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Dense(32, activation='relu'))\n",
    " model.add(Dropout(0.3))\n",
    " model.add(Dense(16, activation='selu'))\n",
    " model.add(Dropout(0.1))\n",
    "\n",
    " sgd = SGD(learning_rate=0.01) \n",
    " model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    " model.fit(X_trn, y_trn, epochs=30, batch_size=32)\n",
    " \n",
    " # Evaluate the model on test data\n",
    " _, test_accuracy = model.evaluate(X_tst, y_tst,verbose=0)\n",
    " \n",
    " # Append test accuracy to the list\n",
    " test_accuracies.append(test_accuracy)\n",
    "# Compute the mean of test accuracies\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print(\"Mean Test Accuracy:\", mean_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200f0ef",
   "metadata": {},
   "source": [
    "Mean test Accuracy for Model 1 is 0.1018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e39be1",
   "metadata": {},
   "source": [
    "Model-2: 4 hidden layers having 128, 64, 32, 16 number of neurons \n",
    "respectively with activation function sigmoid, tanh, relu and selu respectively \n",
    "and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as Adam\n",
    "with batch size set to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b870fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  1\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 4ms/step - loss: 9.7610 - accuracy: 0.0850\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9387 - accuracy: 0.0710\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8079 - accuracy: 0.0900\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8139 - accuracy: 0.0790\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7910 - accuracy: 0.0720\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8261 - accuracy: 0.0900\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8608 - accuracy: 0.0990\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8220 - accuracy: 0.0890\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7833 - accuracy: 0.0880\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7804 - accuracy: 0.0790\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7976 - accuracy: 0.0770\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7857 - accuracy: 0.0760\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7843 - accuracy: 0.0870\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8093 - accuracy: 0.0670\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7858 - accuracy: 0.0940\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0830\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8073 - accuracy: 0.0860\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7820 - accuracy: 0.0770\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7994 - accuracy: 0.0910\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7838 - accuracy: 0.1060\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7853 - accuracy: 0.0950\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7973 - accuracy: 0.0680\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7982 - accuracy: 0.0820\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7986 - accuracy: 0.0810\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0780\n",
      "step:  2\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 11.9340 - accuracy: 0.1040\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3402 - accuracy: 0.0930\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9042 - accuracy: 0.0800\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8296 - accuracy: 0.0790\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8075 - accuracy: 0.0750\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8091 - accuracy: 0.0760\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7942 - accuracy: 0.0770\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8229 - accuracy: 0.0680\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7850 - accuracy: 0.0710\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0720\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0650\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7849 - accuracy: 0.0690\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0610\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0680\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0680\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0590\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0700\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0520\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7846 - accuracy: 0.0590\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0670\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0740\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7847 - accuracy: 0.0730\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0620\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0640\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "step:  3\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 4ms/step - loss: 8.3738 - accuracy: 0.1070\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2217 - accuracy: 0.1180\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9759 - accuracy: 0.1060\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1895 - accuracy: 0.1040\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2459 - accuracy: 0.0970\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2974 - accuracy: 0.0920\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2565 - accuracy: 0.1090\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0065 - accuracy: 0.0950\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9668 - accuracy: 0.0980\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0173 - accuracy: 0.1190\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8733 - accuracy: 0.0890\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8485 - accuracy: 0.1000\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.8802 - accuracy: 0.1020\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2037 - accuracy: 0.0900\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9229 - accuracy: 0.1030\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0611 - accuracy: 0.0850\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9256 - accuracy: 0.1000\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0056 - accuracy: 0.1070\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8168 - accuracy: 0.0880\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6094 - accuracy: 0.0860\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1496 - accuracy: 0.0850\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1684 - accuracy: 0.0980\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8015 - accuracy: 0.0910\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8372 - accuracy: 0.1140\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6773 - accuracy: 0.1010\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6914 - accuracy: 0.1110\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3715 - accuracy: 0.0940\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3252 - accuracy: 0.0910\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4825 - accuracy: 0.1180\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8837 - accuracy: 0.1070\n",
      "step:  4\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 6.7944 - accuracy: 0.0990\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9119 - accuracy: 0.0770\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8430 - accuracy: 0.0850\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8172 - accuracy: 0.0540\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7857 - accuracy: 0.0900\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7983 - accuracy: 0.0750\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7944 - accuracy: 0.0850\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7955 - accuracy: 0.0840\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7845 - accuracy: 0.0810\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7836 - accuracy: 0.0810\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8113 - accuracy: 0.0760\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7962 - accuracy: 0.0880\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7839 - accuracy: 0.0830\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0650\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0700\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0720\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0680\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0750\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "step:  5\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 8.5176 - accuracy: 0.1080\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.9244 - accuracy: 0.1280\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3654 - accuracy: 0.1150\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5476 - accuracy: 0.1210\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3351 - accuracy: 0.1360\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3059 - accuracy: 0.1270\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7844 - accuracy: 0.1630\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5133 - accuracy: 0.1660\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4208 - accuracy: 0.1590\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3442 - accuracy: 0.1540\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6461 - accuracy: 0.1800\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.9347 - accuracy: 0.1270\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0892 - accuracy: 0.1370\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0278 - accuracy: 0.1300\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9893 - accuracy: 0.1240\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2070 - accuracy: 0.1880\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3246 - accuracy: 0.1650\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.7483 - accuracy: 0.1590\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2987 - accuracy: 0.1750\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0651 - accuracy: 0.2190\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3508 - accuracy: 0.1590\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2337 - accuracy: 0.2050\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9967 - accuracy: 0.2230\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1860 - accuracy: 0.2090\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2607 - accuracy: 0.2000\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5046 - accuracy: 0.2080\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4013 - accuracy: 0.1950\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2091 - accuracy: 0.1650\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3418 - accuracy: 0.2100\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0212 - accuracy: 0.2260\n",
      "step:  6\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 4ms/step - loss: 10.8569 - accuracy: 0.1000\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 10.6001 - accuracy: 0.1350\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.0986 - accuracy: 0.1360\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8458 - accuracy: 0.0670\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7926 - accuracy: 0.0710\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0630\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7833 - accuracy: 0.0740\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7966 - accuracy: 0.0830\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7820 - accuracy: 0.0850\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7853 - accuracy: 0.0810\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7825 - accuracy: 0.0730\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7973 - accuracy: 0.0580\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0640\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0740\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7831 - accuracy: 0.0570\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7982 - accuracy: 0.0780\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0640\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0620\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7836 - accuracy: 0.0860\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7839 - accuracy: 0.0630\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8066 - accuracy: 0.0710\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7846 - accuracy: 0.0680\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7853 - accuracy: 0.0770\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7854 - accuracy: 0.0590\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7846 - accuracy: 0.0770\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0660\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "step:  7\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 4ms/step - loss: 8.5806 - accuracy: 0.1090\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.9505 - accuracy: 0.1030\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.0934 - accuracy: 0.1010\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4518 - accuracy: 0.0980\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4069 - accuracy: 0.1020\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5988 - accuracy: 0.1050\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3163 - accuracy: 0.1160\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2175 - accuracy: 0.1190\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3932 - accuracy: 0.0970\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4612 - accuracy: 0.1020\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3349 - accuracy: 0.1040\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4125 - accuracy: 0.1110\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4424 - accuracy: 0.1070\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3465 - accuracy: 0.1280\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4611 - accuracy: 0.0870\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6365 - accuracy: 0.1220\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3266 - accuracy: 0.1120\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3411 - accuracy: 0.1120\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3667 - accuracy: 0.1110\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3346 - accuracy: 0.1040\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.1179 - accuracy: 0.1150\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3507 - accuracy: 0.1080\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2880 - accuracy: 0.1170\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.2236 - accuracy: 0.1210\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3460 - accuracy: 0.1190\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.5229 - accuracy: 0.1040\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4462 - accuracy: 0.1150\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4589 - accuracy: 0.1090\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.6017 - accuracy: 0.1150\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.4107 - accuracy: 0.1100\n",
      "step:  8\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 7.0204 - accuracy: 0.0770\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9665 - accuracy: 0.0910\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9214 - accuracy: 0.0790\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8466 - accuracy: 0.0800\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7985 - accuracy: 0.0910\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7953 - accuracy: 0.0750\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7828 - accuracy: 0.0850\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8047 - accuracy: 0.0790\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0740\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7855 - accuracy: 0.0710\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7839 - accuracy: 0.0680\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7839 - accuracy: 0.0750\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0640\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7827 - accuracy: 0.0730\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0470\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7848 - accuracy: 0.0690\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7833 - accuracy: 0.0760\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7847 - accuracy: 0.0700\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0550\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "step:  9\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 9.6151 - accuracy: 0.0980\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 7.7990 - accuracy: 0.1150\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.7918 - accuracy: 0.1280\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.7507 - accuracy: 0.1000\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.6139 - accuracy: 0.1190\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4337 - accuracy: 0.1140\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1809 - accuracy: 0.1190\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3246 - accuracy: 0.1080\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3960 - accuracy: 0.1230\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0333 - accuracy: 0.1160\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.1897 - accuracy: 0.1070\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3886 - accuracy: 0.1150\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2562 - accuracy: 0.0950\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.8005 - accuracy: 0.1020\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.5480 - accuracy: 0.1110\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3519 - accuracy: 0.1040\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2544 - accuracy: 0.0990\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.9664 - accuracy: 0.1110\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2366 - accuracy: 0.1120\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2259 - accuracy: 0.1170\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2003 - accuracy: 0.1030\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2124 - accuracy: 0.1030\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2082 - accuracy: 0.1310\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4288 - accuracy: 0.1010\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2150 - accuracy: 0.1090\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.0911 - accuracy: 0.1190\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.2553 - accuracy: 0.1120\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.4463 - accuracy: 0.0890\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3046 - accuracy: 0.1040\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 5.3073 - accuracy: 0.1110\n",
      "step:  10\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 7.6246 - accuracy: 0.1050\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8664 - accuracy: 0.0670\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7966 - accuracy: 0.0780\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7821 - accuracy: 0.0720\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8318 - accuracy: 0.0740\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7975 - accuracy: 0.0750\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7935 - accuracy: 0.0800\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7966 - accuracy: 0.0910\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7847 - accuracy: 0.0850\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7847 - accuracy: 0.0820\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8036 - accuracy: 0.0540\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7850 - accuracy: 0.0650\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7967 - accuracy: 0.0720\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7841 - accuracy: 0.0730\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7839 - accuracy: 0.0800\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7836 - accuracy: 0.0800\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0660\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0750\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0660\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0590\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0540\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0680\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0750\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0680\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7841 - accuracy: 0.0580\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0590\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0640\n",
      "Mean Test Accuracy: 0.07300000041723251\n"
     ]
    }
   ],
   "source": [
    "# Number of times to call the model\n",
    "num_calls = 10\n",
    "# List to store test accuracies\n",
    "test_accuracies = []\n",
    "for i in range(num_calls):\n",
    " print(\"step: \",i+1)\n",
    " # Define, compile, and train the model\n",
    " \n",
    " model = keras.Sequential()\n",
    " model.add(Dense(128, activation='sigmoid',input_shape=(784,)))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(64, activation='tanh'))\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Dense(32, activation='relu'))\n",
    " model.add(Dropout(0.3))\n",
    " model.add(Dense(16, activation='selu'))\n",
    " model.add(Dropout(0.1))\n",
    " model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "\n",
    " sgd = Adam(learning_rate=0.01) \n",
    " model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    " model.fit(X_trn, y_trn, epochs=30, batch_size=32)\n",
    " \n",
    " # Evaluate the model on test data\n",
    " _, test_accuracy = model.evaluate(X_tst, y_tst,verbose=0)\n",
    " \n",
    " # Append test accuracy to the list\n",
    " test_accuracies.append(test_accuracy)\n",
    "# Compute the mean of test accuracies\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print(\"Mean Test Accuracy:\", mean_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74dffdc",
   "metadata": {},
   "source": [
    "Mean Test Accurcy for Model 2: 0.073"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995477da",
   "metadata": {},
   "source": [
    "Model-3: 4 hidden layers having 128, 64, 32, 16 number of neurons \n",
    "respectively with activation function sigmoid, tanh, relu and selu respectively \n",
    "and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01366393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  1\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 4ms/step - loss: 3.6568 - accuracy: 0.0890\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8488 - accuracy: 0.0920\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8872 - accuracy: 0.1020\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8605 - accuracy: 0.0850\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8100 - accuracy: 0.0740\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0840\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7866 - accuracy: 0.0980\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0930\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8133 - accuracy: 0.0880\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0800\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0820\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0740\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0870\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0910\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0880\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0810\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8404 - accuracy: 0.0880\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7865 - accuracy: 0.0800\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0930\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0850\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7870 - accuracy: 0.0760\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0700\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7840 - accuracy: 0.0900\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0880\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "step:  2\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 3.5923 - accuracy: 0.0860\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.1080\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0800\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0770\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0850\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7937 - accuracy: 0.0900\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7991 - accuracy: 0.0710\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7857 - accuracy: 0.0830\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8204 - accuracy: 0.0830\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7978 - accuracy: 0.0720\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8116 - accuracy: 0.0740\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0930\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8113 - accuracy: 0.0840\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0850\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0820\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8004 - accuracy: 0.0890\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7974 - accuracy: 0.0860\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0920\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0960\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0680\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "step:  3\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 4.0463 - accuracy: 0.0830\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8667 - accuracy: 0.1020\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0790\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7985 - accuracy: 0.0820\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0780\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8123 - accuracy: 0.0840\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0920\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0860\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0880\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0750\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.1010\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0870\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8131 - accuracy: 0.0920\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7844 - accuracy: 0.0840\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.1010\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0790\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8543 - accuracy: 0.0730\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7849 - accuracy: 0.0900\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8660 - accuracy: 0.0900\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0940\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0830\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7977 - accuracy: 0.0780\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7969 - accuracy: 0.0960\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0930\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.1090\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0710\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0810\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "step:  4\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 4.4460 - accuracy: 0.0950\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8863 - accuracy: 0.0760\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8534 - accuracy: 0.0900\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8396 - accuracy: 0.0800\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0810\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0960\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0880\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0870\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0970\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0900\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7823 - accuracy: 0.0860\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0880\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7996 - accuracy: 0.0840\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0760\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8000 - accuracy: 0.0820\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8102 - accuracy: 0.0680\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0930\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0770\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0720\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0930\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0830\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0810\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0750\n",
      "step:  5\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 5.6526 - accuracy: 0.1000\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8117 - accuracy: 0.0920\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8400 - accuracy: 0.0780\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0860\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7856 - accuracy: 0.0850\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0950\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0970\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0880\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0960\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0860\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0870\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7857 - accuracy: 0.0870\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0880\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0840\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0630\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0940\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0980\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "step:  6\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 4.0858 - accuracy: 0.0870\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8393 - accuracy: 0.0840\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8857 - accuracy: 0.0820\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8899 - accuracy: 0.0960\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9378 - accuracy: 0.0890\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9327 - accuracy: 0.0940\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9461 - accuracy: 0.0720\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8613 - accuracy: 0.0640\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7857 - accuracy: 0.0920\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0760\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0740\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.1160\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0670\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0840\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0880\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0940\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0880\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0950\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "step:  7\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 4ms/step - loss: 5.5207 - accuracy: 0.0840\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8540 - accuracy: 0.0970\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8861 - accuracy: 0.0860\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8751 - accuracy: 0.0680\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9985 - accuracy: 0.0840\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8766 - accuracy: 0.0830\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9594 - accuracy: 0.0820\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8660 - accuracy: 0.0860\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8121 - accuracy: 0.0810\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8365 - accuracy: 0.0980\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8099 - accuracy: 0.0930\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0760\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8232 - accuracy: 0.1050\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0820\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0830\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0790\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8393 - accuracy: 0.0870\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8471 - accuracy: 0.0870\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8927 - accuracy: 0.0770\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0850\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8393 - accuracy: 0.0730\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0740\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8899 - accuracy: 0.0960\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0830\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8794 - accuracy: 0.0690\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0900\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8740 - accuracy: 0.0880\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0720\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8660 - accuracy: 0.0740\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0790\n",
      "step:  8\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 6.4210 - accuracy: 0.0820\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9360 - accuracy: 0.0930\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8541 - accuracy: 0.0750\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8132 - accuracy: 0.0640\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8372 - accuracy: 0.0800\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0780\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0870\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0760\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0800\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.1070\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7852 - accuracy: 0.0810\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.1000\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0720\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0700\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0660\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7842 - accuracy: 0.0920\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0860\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9060 - accuracy: 0.0750\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7991 - accuracy: 0.0760\n",
      "step:  9\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 6.1100 - accuracy: 0.0910\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8519 - accuracy: 0.0810\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8613 - accuracy: 0.0770\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8376 - accuracy: 0.0840\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8205 - accuracy: 0.0910\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7851 - accuracy: 0.0860\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0920\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8096 - accuracy: 0.0900\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7850 - accuracy: 0.0880\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0930\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.1040\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0920\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0930\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0750\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7866 - accuracy: 0.0780\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "step:  10\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 13.4151 - accuracy: 0.0940\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 13.0052 - accuracy: 0.1040\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 6.3468 - accuracy: 0.0790\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.5137 - accuracy: 0.0860\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.4419 - accuracy: 0.0910\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3169 - accuracy: 0.0900\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8755 - accuracy: 0.0890\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8232 - accuracy: 0.0940\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8502 - accuracy: 0.0800\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0870\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0830\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7804 - accuracy: 0.0930\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0750\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0900\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0750\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8522 - accuracy: 0.1000\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0890\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0930\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7971 - accuracy: 0.0710\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0550\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0780\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0880\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0820\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0940\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0800\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0710\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0880\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0930\n",
      "Mean Test Accuracy: 0.08399999886751175\n"
     ]
    }
   ],
   "source": [
    "# Number of times to call the model\n",
    "num_calls = 10\n",
    "# List to store test accuracies\n",
    "test_accuracies = []\n",
    "for i in range(num_calls):\n",
    " print(\"step: \",i+1)\n",
    " # Define, compile, and train the model\n",
    " \n",
    " model = keras.Sequential()\n",
    " model.add(Dense(128, activation='sigmoid',input_shape=(784,)))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(64, activation='tanh'))\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Dense(32, activation='relu'))\n",
    " model.add(Dropout(0.3))\n",
    " model.add(Dense(16, activation='selu'))\n",
    " model.add(Dropout(0.1))\n",
    " model.add(Dense(10, activation='softmax'))\n",
    " \n",
    " sgd = AdamW(learning_rate=0.1) \n",
    " model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    " model.fit(X_trn, y_trn, epochs=30, batch_size=32)\n",
    " \n",
    " # Evaluate the model on test data\n",
    " _, test_accuracy = model.evaluate(X_tst, y_tst,verbose=0)\n",
    " \n",
    " # Append test accuracy to the list\n",
    " test_accuracies.append(test_accuracy)\n",
    "# Compute the mean of test accuracies\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print(\"Mean Test Accuracy:\", mean_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd6265",
   "metadata": {},
   "source": [
    "Mean Test Accuracy for Model 3: 0.0834"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06ef44",
   "metadata": {},
   "source": [
    "Model-4: 4 hidden layers having 128, 64, 32, 16 number of neurons \n",
    "respectively with activation function sigmoid, tanh, relu and selu respectively \n",
    "and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as Nadam\n",
    "with learning rate 0.1 with batch size set to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af4883db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  1\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 4ms/step - loss: 7.8151 - accuracy: 0.0920\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8784 - accuracy: 0.0900\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0660\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7859 - accuracy: 0.0860\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0650\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0670\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7985 - accuracy: 0.0730\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7859 - accuracy: 0.0840\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0710\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0780\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0870\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0740\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7844 - accuracy: 0.0890\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.1060\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0870\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0750\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7841 - accuracy: 0.0810\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "step:  2\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 4ms/step - loss: 4.4173 - accuracy: 0.0740\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8634 - accuracy: 0.0840\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7923 - accuracy: 0.0820\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0890\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7987 - accuracy: 0.0850\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0770\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8250 - accuracy: 0.0690\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.8860 - accuracy: 0.0710\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8494 - accuracy: 0.0710\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8380 - accuracy: 0.0870\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7832 - accuracy: 0.0730\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8733 - accuracy: 0.0880\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7972 - accuracy: 0.0920\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7842 - accuracy: 0.0810\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7832 - accuracy: 0.0910\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0890\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8100 - accuracy: 0.1000\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0920\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0790\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0780\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0770\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0880\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7832 - accuracy: 0.0940\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0630\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0840\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0970\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0960\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0770\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.8126 - accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0850\n",
      "step:  3\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 3ms/step - loss: 12.8320 - accuracy: 0.1080\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 13.0261 - accuracy: 0.1160\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 12.8454 - accuracy: 0.1170\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.2061 - accuracy: 0.1180\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.3893 - accuracy: 0.0990\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.0214 - accuracy: 0.0820\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8660 - accuracy: 0.0950\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9194 - accuracy: 0.0810\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0900\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8392 - accuracy: 0.0760\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0770\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8232 - accuracy: 0.0730\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8232 - accuracy: 0.0800\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8232 - accuracy: 0.0830\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8527 - accuracy: 0.0810\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8632 - accuracy: 0.0810\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0670\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8259 - accuracy: 0.0750\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0770\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0820\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0860\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8126 - accuracy: 0.0830\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0910\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0740\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7965 - accuracy: 0.0850\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8124 - accuracy: 0.0930\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7870 - accuracy: 0.0820\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0720\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7859 - accuracy: 0.0850\n",
      "step:  4\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 3ms/step - loss: 4.7999 - accuracy: 0.0820\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8088 - accuracy: 0.0830\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0870\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8389 - accuracy: 0.0980\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8118 - accuracy: 0.0840\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0720\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.7859 - accuracy: 0.0870\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0890\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0740\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0760\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0860\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7993 - accuracy: 0.0830\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0640\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7866 - accuracy: 0.0850\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0930\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0860\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0980\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0870\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0830\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8511 - accuracy: 0.0790\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8260 - accuracy: 0.0820\n",
      "step:  5\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 3ms/step - loss: 4.7965 - accuracy: 0.0760\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9483 - accuracy: 0.0860\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9153 - accuracy: 0.0730\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8885 - accuracy: 0.0910\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0950\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8117 - accuracy: 0.0920\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0750\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7832 - accuracy: 0.0650\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0990\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8099 - accuracy: 0.0900\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0660\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0940\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0720\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7981 - accuracy: 0.0790\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7979 - accuracy: 0.0840\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0920\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0920\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0950\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0740\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7851 - accuracy: 0.0910\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8379 - accuracy: 0.0710\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7859 - accuracy: 0.0910\n",
      "step:  6\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 4ms/step - loss: 12.7914 - accuracy: 0.1060\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.0957 - accuracy: 0.0890\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.9229 - accuracy: 0.1040\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7859 - accuracy: 0.0880\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7852 - accuracy: 0.0780\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0770\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7840 - accuracy: 0.0770\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0820\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0660\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0870\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7866 - accuracy: 0.0850\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0910\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0960\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0850\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7832 - accuracy: 0.0680\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0910\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0770\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0860\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0840\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0880\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0790\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0800\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0900\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0770\n",
      "step:  7\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 4ms/step - loss: 4.1644 - accuracy: 0.0780\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0700\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7847 - accuracy: 0.0870\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0800\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0960\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0990\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0980\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7858 - accuracy: 0.0900\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0650\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0740\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.1040\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0730\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0950\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0880\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0660\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7698 - accuracy: 0.0970\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0950\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0940\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0880\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0740\n",
      "step:  8\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 3ms/step - loss: 5.4925 - accuracy: 0.0670\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8352 - accuracy: 0.0840\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7839 - accuracy: 0.0800\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0630\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7851 - accuracy: 0.0800\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7869 - accuracy: 0.0910\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.1000\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0920\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0670\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0860\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0960\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0720\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0710\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0780\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "step:  9\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 4ms/step - loss: 4.2436 - accuracy: 0.0840\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7859 - accuracy: 0.0820\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0820\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.8873 - accuracy: 0.0830\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.8509 - accuracy: 0.0800\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7857 - accuracy: 0.1000\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7859 - accuracy: 0.0800\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0930\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0870\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0760\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0920\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0750\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0810\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0700\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0650\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0930\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0900\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0800\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0850\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0910\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0810\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0990\n",
      "step:  10\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 3ms/step - loss: 6.1498 - accuracy: 0.0680\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0840\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7866 - accuracy: 0.0880\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0720\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0730\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0940\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7863 - accuracy: 0.0950\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7978 - accuracy: 0.0790\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7979 - accuracy: 0.1000\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0670\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0820\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0890\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7974 - accuracy: 0.0770\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0690\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.1070\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0810\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0910\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0790\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0840\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0750\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0830\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0700\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7726 - accuracy: 0.0900\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7993 - accuracy: 0.0720\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.7859 - accuracy: 0.0850\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7993 - accuracy: 0.0700\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7951 - accuracy: 0.0800\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0880\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7726 - accuracy: 0.0890\n",
      "Mean Test Accuracy: 0.08399999886751175\n"
     ]
    }
   ],
   "source": [
    "# Number of times to call the model\n",
    "num_calls = 10\n",
    "# List to store test accuracies\n",
    "test_accuracies = []\n",
    "for i in range(num_calls):\n",
    " print(\"step: \",i+1)\n",
    " # Define, compile, and train the model\n",
    " \n",
    " model = keras.Sequential()\n",
    " model.add(Dense(128, activation='sigmoid',input_shape=(784,)))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(64, activation='tanh'))\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Dense(32, activation='relu'))\n",
    " model.add(Dropout(0.3))\n",
    " model.add(Dense(16, activation='selu'))\n",
    " model.add(Dropout(0.1))\n",
    " model.add(Dense(10, activation='softmax'))\n",
    " \n",
    " sgd = Nadam(learning_rate=0.1) \n",
    " model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    " model.fit(X_trn, y_trn, epochs=30, batch_size=32)\n",
    " \n",
    " # Evaluate the model on test data\n",
    " _, test_accuracy = model.evaluate(X_tst, y_tst,verbose=0)\n",
    " \n",
    " # Append test accuracy to the list\n",
    " test_accuracies.append(test_accuracy)\n",
    "# Compute the mean of test accuracies\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print(\"Mean Test Accuracy:\", mean_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed687c",
   "metadata": {},
   "source": [
    "Mean Test Accuracy for Model 4: 0.0834"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdbf872",
   "metadata": {},
   "source": [
    "2. Tune the hyperparameters using kerastuner to select the best learning rate among the \n",
    "set {0.1, 0.01, 0.15} with batch size varying between {4,8,16} and first hidden layer \n",
    "neurons varying between 250 to 260 with a step value of 2. 2nd, 3rd and 4th hidden \n",
    "layer contains 16, 8, 4 numbers of neurons respectively. The four layers have \n",
    "activation function sigmoid, tanh, relu and selu respectively. Use optimizer as SGD \n",
    "and find the best hyperparameters to predict the MNIST test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d62bd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    " \n",
    " hp_neurons = hp.Int('neurons', min_value=250, max_value=260, step=2)\n",
    " \n",
    " model = keras.Sequential()\n",
    " model.add(Dense(units=hp_neurons, activation='sigmoid',input_shape=(784,)))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(16, activation='tanh'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(8, activation='relu'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(4, activation='selu'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(10, activation='softmax'))\n",
    " \n",
    " # Tune learning rate and batch size\n",
    " hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.15])\n",
    " hp_batch_size = hp.Choice('batch_size', values=[4, 8, 16])\n",
    " # Compile the model\n",
    " model.compile(optimizer=keras.optimizers.SGD(learning_rate=hp_learning_rate),\n",
    " loss='sparse_categorical_crossentropy',\n",
    " metrics=['accuracy'])\n",
    " \n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75f5eb75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configure the tuner\n",
    "tuner = RandomSearch(\n",
    " build_model,\n",
    " objective='val_accuracy',\n",
    " max_trials=10,\n",
    " executions_per_trial=4,\n",
    " directory='keras_tuner_b',\n",
    " project_name='mnist_hyperparameters'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f16f0417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 46s]\n",
      "val_accuracy: 0.1340000033378601\n",
      "\n",
      "Best val_accuracy So Far: 0.1340000033378601\n",
      "Total elapsed time: 00h 07m 42s\n"
     ]
    }
   ],
   "source": [
    "hp_batch_size = tuner.oracle.get_space()['batch_size']\n",
    "tuner.search(X_trn, y_trn, epochs=15, validation_data=(X_tst, y_tst), batch_size=hp_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24a78794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neurons: 256\n",
      "Best learning rate: 0.15\n",
      "Best batch size: 16\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.3004 - accuracy: 0.1340\n",
      "Test accuracy of the best model: 0.1340000033378601\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=20)[0]\n",
    "best_neurons = best_hps.get('neurons')\n",
    "best_learning_rate = best_hps.get('learning_rate')\n",
    "best_batch_size = best_hps.get('batch_size')\n",
    "print(f\"Best number of neurons: {best_neurons}\")\n",
    "print(f\"Best learning rate: {best_learning_rate}\")\n",
    "print(f\"Best batch size: {best_batch_size}\")\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(X_tst, y_tst)\n",
    "print(f\"Test accuracy of the best model: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d3e3c",
   "metadata": {},
   "source": [
    "Best Accuracy with hyperparameter tuning : 0.134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d465438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205294 (801.93 KB)\n",
      "Trainable params: 205294 (801.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f26bfb",
   "metadata": {},
   "source": [
    "Observations: \n",
    "\n",
    "Mean test Accuracy for Model 1 is 0.1018\n",
    "\n",
    "Mean Test Accurcy for Model 2: 0.073\n",
    "\n",
    "Mean Test Accuracy for Model 3: 0.0834\n",
    "\n",
    "Mean Test Accuracy for Model 4: 0.0834\n",
    "\n",
    "Best Accuracy with hyperparameter tuning : 0.134\n",
    "\n",
    "Hence Hyperparameter tuning shows the highest accuracy among all the methods listed above\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
